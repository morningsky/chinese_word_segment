{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'为  寂寞  的  夜空  画上  一个  月亮'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import jieba\n",
    "seg_sent = jieba.cut(u\"为寂寞的夜空画上一个月亮\") #精准模式\n",
    "'  '.join(seg_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded succeed\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'为 寂寞 的 夜空 画 上 一个 月亮'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import thulac\n",
    "thu = thulac.thulac(seg_only=True)\n",
    "seg_sent = thu.cut(\"为寂寞的夜空画上一个月亮\",text=True)\n",
    "seg_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'为     寂  寞     的     夜  空     画     上     一  个     月  亮'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'  '.join(list(seg_sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'为  寂寞  的  夜空  画  上  一个  月亮'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pynlpir\n",
    "pynlpir.open()\n",
    "seg_sent = pynlpir.segment(\"为寂寞的夜空画上一个月亮\", pos_tagging=False)\n",
    "'  '.join(seg_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'为  寂寞  的  夜空  画  上  一个  月亮'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyltp import Segmentor\n",
    "segmentor = Segmentor()  # 初始化实例\n",
    "segmentor.load('cws.model')  # 加载模型\n",
    "seg_sent = segmentor.segment('为寂寞的夜空画上一个月亮')  # 分词\n",
    "'  '.join(seg_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'为  寂寞  的  夜空画  上  一个  月亮'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import fool\n",
    "seg_sent = fool.cut(\"为寂寞的夜空画上一个月亮\",ignore=True)\n",
    "'  '.join(seg_sent[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load cws info from rnn_cws/cws2.info\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'为 寂寞 的 夜空 画 上 一个 月 亮 '"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%run rnn_cws/test_keras_model.py\n",
    "model = loadModel('rnn_cws/cws2_keras.model','rnn_cws/cws2_keras.weights' )\n",
    "cwsInfo = cws.loadCwsInfo('rnn_cws/cws2.info')\n",
    "seg_sent = cwsSent(\"为寂寞的夜空画上一个月亮\", model, cwsInfo)\n",
    "seg_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jieba used time: %d s 0.6560442447662354\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import jieba\n",
    "\n",
    "start_time = time.time()\n",
    "fname = 'dataset/pku_test.utf8'\n",
    "fd = codecs.open(fname, 'r', 'utf-8')\n",
    "lines = fd.readlines()\n",
    "fd.close()\n",
    "dstname = 'dataset/pku_jieba.utf8'\n",
    "fd = open(dstname, 'w', encoding='utf-8')\n",
    "for line in lines:\n",
    "    #rst = cwsSent(line.strip(), model, cwsInfo)\n",
    "    #fd.write(rst.encode('utf-8' + '\\n')\n",
    "    seg_sent = jieba.cut(line.strip())\n",
    "    fd.write('  '.join(seg_sent) + '\\n')\n",
    "fd.close()\n",
    "end_time = time.time()\n",
    "print(\"Jieba used time: %d s\",(end_time-start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded succeed\n",
      "THULAC used time: %d s 6.259702444076538\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "import thulac\n",
    "thu = thulac.thulac(seg_only=True)\n",
    "\n",
    "fname = 'dataset/pku_test.utf8'\n",
    "fd = codecs.open(fname, 'r', 'utf-8')\n",
    "lines = fd.readlines()\n",
    "fd.close()\n",
    "dstname = 'dataset/pku_thu.utf8'\n",
    "fd = open(dstname, 'w', encoding='utf-8')\n",
    "for line in lines:\n",
    "    #rst = cwsSent(line.strip(), model, cwsInfo)\n",
    "    #fd.write(rst.encode('utf-8' + '\\n')\n",
    "    seg_sent = thu.cut(line.strip(),text=True)\n",
    "    fd.write(seg_sent + '\\n')\n",
    "fd.close()\n",
    "end_time = time.time()\n",
    "print(\"THULAC used time: %d s\",(end_time-start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLPIR used time: %d s 0.462904691696167\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "import pynlpir\n",
    "pynlpir.open()\n",
    "\n",
    "fname = 'dataset/pku_test.utf8'\n",
    "fd = codecs.open(fname, 'r', 'utf-8')\n",
    "lines = fd.readlines()\n",
    "fd.close()\n",
    "dstname = 'dataset/pku_nlpir.utf8'\n",
    "fd = open(dstname, 'w', encoding='utf-8')\n",
    "for line in lines:\n",
    "    #rst = cwsSent(line.strip(), model, cwsInfo)\n",
    "    #fd.write(rst.encode('utf-8' + '\\n')\n",
    "    seg_sent = pynlpir.segment(line.strip(), pos_tagging=False)\n",
    "    fd.write('  '.join(seg_sent) + '\\n')\n",
    "fd.close()\n",
    "end_time = time.time()\n",
    "print(\"NLPIR used time: %d s\",(end_time-start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PYLTP used time: %d s 1.992269515991211\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "from pyltp import Segmentor\n",
    "segmentor = Segmentor()  # 初始化实例\n",
    "segmentor.load('cws.model')  # 加载模型\n",
    "\n",
    "fname = 'dataset/pku_test.utf8'\n",
    "fd = codecs.open(fname, 'r', 'utf-8')\n",
    "lines = fd.readlines()\n",
    "fd.close()\n",
    "dstname = 'dataset/pku_ltp.utf8'\n",
    "fd = open(dstname, 'w', encoding='utf-8')\n",
    "for line in lines:\n",
    "    #rst = cwsSent(line.strip(), model, cwsInfo)\n",
    "    #fd.write(rst.encode('utf-8' + '\\n')\n",
    "    seg_sent = segmentor.segment(line.strip())\n",
    "    fd.write('  '.join(seg_sent) + '\\n')\n",
    "fd.close()\n",
    "end_time = time.time()\n",
    "print(\"PYLTP used time: %d s\",(end_time-start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOOL used time: %d s 12.528725862503052\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "import fool\n",
    "fname = 'dataset/pku_test.utf8'\n",
    "fd = codecs.open(fname, 'r', 'utf-8')\n",
    "lines = fd.readlines()\n",
    "fd.close()\n",
    "dstname = 'dataset/pku_fool.utf8'\n",
    "fd = open(dstname, 'w', encoding='utf-8')\n",
    "for line in lines:\n",
    "    #rst = cwsSent(line.strip(), model, cwsInfo)\n",
    "    #fd.write(rst.encode('utf-8' + '\\n')\n",
    "    seg_sent = fool.cut(line.strip(),ignore=True)\n",
    "    fd.write('  '.join(seg_sent[0]) + '\\n')\n",
    "fd.close()\n",
    "end_time = time.time()\n",
    "print(\"FOOL used time: %d s\",(end_time-start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking : expected embedding_1_input to have shape (7,) but got array with shape (1,)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-120-e51b7c4afac7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mfd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdstname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'w'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mseg_sent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcwsSent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcwsInfo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[1;31m#fd.write(rst.encode('utf-8' + '\\n')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mfd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseg_sent\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'\\n'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\NLP\\Score_test\\rnn_cws\\test_keras_model.py\u001b[0m in \u001b[0;36mcwsSent\u001b[1;34m(sent, model, cwsInfo)\u001b[0m\n\u001b[0;32m     46\u001b[0m     \u001b[0mvec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcws\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msent2vec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvocab\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mctxWindows\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m7\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[0mvec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m     \u001b[0mprobs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     49\u001b[0m     \u001b[1;31m#classes = model.predict_classes(vec)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[1;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[0;32m   1110\u001b[0m             \u001b[0mA\u001b[0m \u001b[0mNumpy\u001b[0m \u001b[0marray\u001b[0m \u001b[0mof\u001b[0m \u001b[0mprobability\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1111\u001b[0m         \"\"\"\n\u001b[1;32m-> 1112\u001b[1;33m         \u001b[0mpreds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1113\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mpreds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0.\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mpreds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1.\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1114\u001b[0m             warnings.warn('Network returning invalid probability values. '\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[0;32m   1023\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1024\u001b[0m         return self.model.predict(x, batch_size=batch_size, verbose=verbose,\n\u001b[1;32m-> 1025\u001b[1;33m                                   steps=steps)\n\u001b[0m\u001b[0;32m   1026\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1027\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpredict_on_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[0;32m   1815\u001b[0m         x = _standardize_input_data(x, self._feed_input_names,\n\u001b[0;32m   1816\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_feed_input_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1817\u001b[1;33m                                     check_batch_axis=False)\n\u001b[0m\u001b[0;32m   1818\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstateful\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1819\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    121\u001b[0m                             \u001b[1;34m': expected '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' to have shape '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' but got array with shape '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 123\u001b[1;33m                             str(data_shape))\n\u001b[0m\u001b[0;32m    124\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking : expected embedding_1_input to have shape (7,) but got array with shape (1,)"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "fname = 'dataset/pku_test.utf8'\n",
    "fd = codecs.open(fname, 'r', 'utf-8')\n",
    "lines = fd.readlines()\n",
    "fd.close()\n",
    "dstname = 'dataset/pku_bilstm.utf8'\n",
    "fd = open(dstname, 'w', encoding='utf-8')\n",
    "for line in lines:\n",
    "    seg_sent = cwsSent(line.strip(), model, cwsInfo)\n",
    "    #fd.write(rst.encode('utf-8' + '\\n')\n",
    "    fd.write(seg_sent + '\\n')\n",
    "fd.close()\n",
    "end_time = time.time()\n",
    "print(\"Bi_LSTM used time: %d s\",(end_time-start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "#从json文件中加载已存模型\n",
    "json_file = open('cws.keras_model', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "\n",
    "from keras.models import model_from_json\n",
    "loaded_model = model_from_json(loaded_model_json)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
